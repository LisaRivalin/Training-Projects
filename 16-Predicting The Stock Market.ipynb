{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "<center>\n",
    "Dataquest Guided Project 16:\n",
    "Predicting The Stock Market\n",
    "</center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is part of the Dataquest program.\n",
    "\n",
    "- part of paths **Data Scientist in Python**\n",
    "    - Step 6: **Machine Learning**\n",
    "        - Course 5:**Machine Learning in Python : Intermediate **\n",
    "            - Logistic Regression\n",
    "            - Evaluating Binary Classifiers\n",
    "            - Multiclass Classification\n",
    "            - Clustering basics\n",
    "            - K-Means clustering\n",
    "            - Gradient Descent\n",
    "            - Introduction to Neural networks\n",
    "            \n",
    "As this is a guided project, we are following and deepening the steps suggested by Dataquest. In this project, we will practice to use a dataset to develop a predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case : Predicting The Stock Market"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be working with data from the [S&P500 Index](https://en.wikipedia.org/wiki/S%26P_500_Index), a stock market index. We'll be using historical data on the price of the S&P Index to make predictions about the future prices. Predicting whether an index will go up or go down sill help us forecast how the stock market as a whole will perform. \n",
    "\n",
    "We'll be working with a csv file containing index prices. Each row in the file contains a daily record of the price of the S&P500 Index from 1950 to 2015. The dataset is stored in sphist.csv. \n",
    "\n",
    "The columns of the dataset are : \n",
    "\n",
    "| Header | Definition   |\n",
    "|------|------|\n",
    "|   **Date**  | the date of the record|\n",
    "|   **Open**  | the opening price of the day (when trading starts)|\n",
    "|   **High**  | the highest trade price during the day|\n",
    "|   **Low**  | the lowest trade price during the day|\n",
    "|   **Close**  | the closing price for the day (when trading is finished)|\n",
    "|   **Volume**  | the number of shares traded|\n",
    "|   **Adj Close**  | the daily closing price, adjusted retroactively to include any corporate actions|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sphist.csv\")\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.sort_values(\"Date\", ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets taken from the stock market need to be handled differently than dataset from other sectors when it comes time to make predictions. In other machine learning exercises, we can treat each row as independent. Stock market data is sequential, and each observation comes a day after the previous observation. Thrus, the observations are not all independent, and we can't treat them as such.\n",
    "\n",
    "We have to be careful to not inject \"future\" knowledge into past rows when we do training and prediction. Thus, we will generate the following indicators :\n",
    "- The average price from the past 5 days.\n",
    "- The average price for the past 30 days.\n",
    "- The average price for the past 365 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['5 Days Open'] = df['Open'].rolling(center=False, window=5).mean()\n",
    "df['5 Days High'] = df['High'].rolling(center=False, window=5).mean()\n",
    "df['5 Days Low'] = df['Low'].rolling(center=False, window=5).mean()\n",
    "df['5 Days Volume'] = df['Volume'].rolling(center=False, window=5).mean()\n",
    "\n",
    "df['Year'] = df['Date'].apply(lambda x: x.year)\n",
    "\n",
    "#Adding Day of week column and set it to categorical\n",
    "df['DOW'] = df['Date'].apply(lambda x: x.weekday())\n",
    "dow_df = pd.get_dummies(df['DOW'])\n",
    "df = pd.concat([df, dow_df], axis=1)\n",
    "df = df.drop(['DOW'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting up the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're computing indicators that use historical data, there are some rows where there isn't enough historical data to generate them. \n",
    "Some of the indicators use 365 days of historical data, and the dataset starts on 1950-01-03. Thus, any rows that fall before 1951-01-03 don't have enough historical data to compute all the indicators, we'll remove this before splitting the data between training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Date'] >= datetime(year=1951, month=1, day=3)]\n",
    "df.dropna(axis=0)\n",
    "\n",
    "train = df[df['Date'] < datetime(year=2013, month=1, day=1)]\n",
    "test = df[df['Date'] >= datetime(year=2013, month=1, day=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['5 Days Open', '5 Days Volume', '5 Days High', '5 Days Low', 'Year', 0, 1, 2, 3, 4]\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(train[features], train['Close'])\n",
    "predictions = lr.predict(test[features])\n",
    "\n",
    "mae = mean_absolute_error(test['Close'] ,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.11778468411\n"
     ]
    }
   ],
   "source": [
    "print(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now predict the S&P500 ! We can still generate new indicators to improve our model, here are some ideas : \n",
    "\n",
    "- The ratio between the average volume for the past five days, and the average volume for the past year.\n",
    "- The standard deviation of the average volume over the past five days.\n",
    "- The standard deviation of the average volume over the past year.\n",
    "- The ratio between the standard deviation of the average volume for the past five days, and the standard deviation of the average volume for the past year.\n",
    "- The ratio between the lowest price in the past year and the current price.\n",
    "- The ratio between the highest price in the past year and the current price.\n",
    "- The number of holidays in the prior month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
